{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Link property prediction on ogbl-ppa.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOk70+PNGbIGTImSoa0NCcV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"JHyXITl-7Cdi","executionInfo":{"status":"ok","timestamp":1652512786517,"user_tz":-120,"elapsed":7,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"outputs":[],"source":["# Ignore warning\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3644,"status":"ok","timestamp":1652512790155,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"},"user_tz":-120},"id":"ib8_3-Scxvk8","outputId":"9d9da3f3-55d3-4873-ac1c-ef99c746728e"},"outputs":[{"output_type":"stream","name":"stdout","text":["All good, a Gpu is available\n"]}],"source":["# Set device to gpu if available\n","import torch\n","device = 'cpu'\n","if torch.cuda.is_available:\n","  print('All good, a Gpu is available')\n","  device = torch.device(\"cuda:0\")  \n","else:\n","  print('Please set GPU via Edit -> Notebook Settings.')\n","  "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1652512790156,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"},"user_tz":-120},"id":"I8YXWMiA7fVB","outputId":"d0f913a5-a715-4c70-f701-b90aed223f97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat May 14 07:18:40 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","\n","!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install -q torch-geometric\n","!pip install -q ogb"],"metadata":{"id":"xP-wrPR_N6FH","executionInfo":{"status":"ok","timestamp":1652512813000,"user_tz":-120,"elapsed":22850,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"64d1425f-83a0-4b4c-85ed-5d89085a94a6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 7.9 MB 8.8 MB/s \n","\u001b[K     |████████████████████████████████| 3.5 MB 8.3 MB/s \n","\u001b[K     |████████████████████████████████| 407 kB 9.9 MB/s \n","\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 78 kB 4.8 MB/s \n","\u001b[?25h  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["# Import modules\n","import networkx as nx\n","from torch_geometric.utils.convert import to_networkx\n","\n","import tqdm\n","import time\n","import sys\n","import os\n","import math\n","import random\n","\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch_geometric.utils import negative_sampling\n","\n","import numpy as np\n","\n","import pandas as  pd\n","\n","import seaborn as sns\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import cm, colors\n","\n","from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n","\n","import torch_geometric.transforms as T\n","from torch_sparse import SparseTensor\n","from torch_geometric.nn import GCNConv, SAGEConv\n","\n","from sklearn.metrics import roc_auc_score"],"metadata":{"id":"HvrqBRxTckR4","executionInfo":{"status":"ok","timestamp":1652512814569,"user_tz":-120,"elapsed":1591,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LPmh48qzlrzk"},"source":["## Reproducibility\n","When **developing and debugging** Neural Networks is desirable to have a deterministic behaviour. For this reason, we are going to disable all the sources of randomness. Please note that completely reproducible results are not guaranteed across PyTorch releases, individual commits or different platforms. You can find more detailed information at this [page](https://pytorch.org/docs/stable/notes/randomness.html).\n","Please note that the flag `cudnn.benchmark = False` disable the auto-tuner that selects the optimal set of algorithms for your hardware and usually leads to slower runtime. "]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FIz_r1nZH7RN","executionInfo":{"status":"ok","timestamp":1652512814570,"user_tz":-120,"elapsed":15,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"outputs":[],"source":["def fix_random(seed: int) -> None:\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    \n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True        "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"VOllsYHuIZHY","executionInfo":{"status":"ok","timestamp":1652512814570,"user_tz":-120,"elapsed":14,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"outputs":[],"source":["fix_random(42)"]},{"cell_type":"markdown","metadata":{"id":"52uL5ycXOCEI"},"source":["## The Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"A4PUTnuRTHI4","executionInfo":{"status":"ok","timestamp":1652512814571,"user_tz":-120,"elapsed":15,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"outputs":[],"source":["# dataset = PygLinkPropPredDataset(name=\"ogbl-ddi\", root='datasets/')\n","# evaluator = Evaluator(name='ogbl-ddi')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZnnOzTAJG5Tf","executionInfo":{"status":"ok","timestamp":1652512814572,"user_tz":-120,"elapsed":15,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"outputs":[],"source":["# dataset = PygLinkPropPredDataset(name=\"ogbl-collab\", root='datasets/')\n","# evaluator = Evaluator(name='ogbl-collab')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"eYCKYN5iFLkD","executionInfo":{"status":"ok","timestamp":1652512846312,"user_tz":-120,"elapsed":31754,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"720686cb-2ba1-41d2-898a-67d540ac59a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://snap.stanford.edu/ogb/data/linkproppred/ppassoc.zip\n"]},{"output_type":"stream","name":"stderr","text":["Downloaded 0.38 GB: 100%|██████████| 388/388 [00:04<00:00, 87.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting datasets/ppassoc.zip\n"]},{"output_type":"stream","name":"stderr","text":["Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Loading necessary files...\n","This might take a while.\n","Processing graphs...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Converting graphs into PyG objects...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 5637.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving...\n"]},{"output_type":"stream","name":"stderr","text":["Done!\n"]}],"source":["dataset = PygLinkPropPredDataset(name=\"ogbl-ppa\", root='datasets/')\n","evaluator = Evaluator(name='ogbl-ppa')"]},{"cell_type":"code","source":["data = dataset[0]\n","edge_index = data.edge_index.to(device)\n","data.x = data.x.to(torch.float)\n","if data.edge_weight is not None:\n","    data.edge_weight = data.edge_weight.view(-1).to(torch.float)\n","\n","transform = T.Compose([\n","    # T.NormalizeFeatures(),\n","    T.RemoveIsolatedNodes(),\n","    T.ToSparseTensor(),\n","])\n","data = transform(data)"],"metadata":{"id":"fYhp0Q1UJ6l5","executionInfo":{"status":"ok","timestamp":1652512876749,"user_tz":-120,"elapsed":30445,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5353,"status":"ok","timestamp":1652512882095,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"},"user_tz":-120},"id":"38cpkrT9CPNG","outputId":"a99c9c2f-c4c7-462b-e272-1e825bba728d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Dataset: ogbl-ppa:\n","==================\n","Number of graphs: 1\n","Number of features: 58\n","Number of classes: 0\n","\n","Data(num_nodes=576289, x=[576289, 58], adj_t=[576289, 576289, nnz=42463862])\n","=======================================================================\n","Number of nodes: 576289\n","Number of edges: 42463862\n","Average node degree: 73.69\n","Has isolated nodes: False\n","Has self-loops: False\n","Is undirected: True\n"]}],"source":["print()\n","print(f'Dataset: {dataset.name}:')\n","print('==================')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","\n","print()\n","print(data)\n","print('=======================================================================')\n","\n","# Gather some statistics about the graph.\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n","print(f'Has self-loops: {data.has_self_loops()}')\n","print(f'Is undirected: {data.is_undirected()}')"]},{"cell_type":"markdown","source":["##Model Definition"],"metadata":{"id":"fJCFntqQw4Cq"}},{"cell_type":"code","source":["class GCN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n","        super(GCN, self).__init__()\n","\n","        self.convs = torch.nn.ModuleList()\n","        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n","        for _ in range(num_layers - 2):\n","            self.convs.append(\n","                GCNConv(hidden_channels, hidden_channels, cached=True))\n","        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n","\n","        self.dropout = dropout\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","\n","    def forward(self, x, adj_t):\n","        for conv in self.convs[:-1]:\n","            x = conv(x, adj_t)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.convs[-1](x, adj_t)\n","        return x"],"metadata":{"id":"1fUdZF9_epjH","executionInfo":{"status":"ok","timestamp":1652512882096,"user_tz":-120,"elapsed":25,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class SAGE(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n","        super(SAGE, self).__init__()\n","\n","        self.convs = torch.nn.ModuleList()\n","        self.convs.append(SAGEConv(in_channels, hidden_channels))\n","        for _ in range(num_layers - 2):\n","            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n","        self.convs.append(SAGEConv(hidden_channels, out_channels))\n","\n","        self.dropout = dropout\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","\n","    def forward(self, x, adj_t):\n","        for conv in self.convs[:-1]:\n","            x = conv(x, adj_t)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.convs[-1](x, adj_t)\n","        return x"],"metadata":{"id":"Bk7tJaAtesBT","executionInfo":{"status":"ok","timestamp":1652512882097,"user_tz":-120,"elapsed":24,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from torch.nn import Sequential, Linear, Dropout\n","class SAGE2(torch.nn.Module):\n","    def __init__(self, in_dim, hid_dim, out_dim, n_layers, p_drop, skip_conn=False, post_proc_MLP=False):\n","        super(SAGE2, self).__init__()\n","\n","        if n_layers < 1:\n","            raise AssertionError('Number or convolution layer must be at least 1')\n","\n","        self.p_drop = p_drop\n","        self.n_layers = n_layers\n","        self.skip_conn = skip_conn\n","\n","        self.convs = torch.nn.ModuleList()\n","        for i in range(n_layers):\n","            conv = SAGEConv(in_dim, hid_dim, normalize=True, aggr=\"add\")\n","            in_dim = hid_dim\n","            self.convs.append(conv)\n","\n","        self.post_proc_MLP = post_proc_MLP\n","        if post_proc_MLP:\n","            self.post_MLP = Sequential(\n","                Linear(in_dim, hid_dim), Dropout(self.p_drop),\n","                Linear(hid_dim, out_dim)\n","            )\n","        else:\n","            self.convs[-1] = SAGEConv(in_dim, out_dim, normalize=True, aggr=\"add\")\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","        if self.post_proc_MLP:\n","            self.post_MLP.reset_parameters()\n","\n","    def forward(self, x, adj_t):\n","        x_prev = None\n","        for conv in self.convs[:-1]:\n","            x = conv(x, adj_t)\n","\n","            if self.skip_conn and x_prev is not None:\n","                x = x + x_prev\n","            \n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.p_drop, training=self.training)\n","            x_prev = x\n","            \n","        if self.post_proc_MLP:\n","            x = self.convs[-1](x, adj_t)\n","            x = self.post_MLP(x)\n","        else:\n","            x = self.convs[-1](x, adj_t)\n","\n","        return x"],"metadata":{"executionInfo":{"status":"ok","timestamp":1652512882098,"user_tz":-120,"elapsed":25,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}},"id":"y1ODLW8ZKpRS"},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HWonCG3DMVqv"},"source":["The LinkPredictor takes the embedding vector of 2 nodes ($h_i$, $h_j \\in \\mathbb{R}^d$ ) and computes the probability score of whether there exists a link between the 2 nodes.\n","\n","$$\\text{Probability of edge between node i and node j = MLP}(h_i\\odot h_j)$$\n","\n","Note: $x \\odot y$ is the element-wise product (Hadamard product) of vectors $x$ and $y$"]},{"cell_type":"code","source":["class LinkPredictor(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,  dropout):\n","        super(LinkPredictor, self).__init__()\n","\n","        self.lins = torch.nn.ModuleList()\n","        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n","        for _ in range(num_layers - 2):\n","            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n","        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n","\n","        self.dropout = dropout\n","\n","    def reset_parameters(self):\n","        for lin in self.lins:\n","            lin.reset_parameters()\n","\n","    def forward(self, x_i, x_j):\n","        x = x_i * x_j\n","        for lin in self.lins[:-1]:\n","            x = lin(x)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.lins[-1](x)\n","        return torch.sigmoid(x)"],"metadata":{"id":"ay6clbWWenXs","executionInfo":{"status":"ok","timestamp":1652512882098,"user_tz":-120,"elapsed":24,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9gMp7rnRcS77"},"source":["## Train and evaluation"]},{"cell_type":"markdown","metadata":{"id":"5ScmUiUCNy6z"},"source":["The model is trained by jointly maximizing the probabilty prediction of correct edges and minimizing the probability prediciton of the incorrect edges:\n","\n","$Loss = -\\log(prob\\_pos\\_edges  + ϵ) - \\log(1-prob\\_neg\\_edges + ϵ)$ where the $ϵ=10^{-15}$ is added to each term for numerical stability"]},{"cell_type":"code","source":["def train(model, predictor, node_feats, adj_t, split_edge, optimizer, batch_size):\n","    model.train()\n","    predictor.train()\n","\n","    pos_train_edge = split_edge['train']['edge'].to(device)\n","\n","    total_loss = total_examples = 0\n","    for edge_id in DataLoader(range(pos_train_edge.size(0)), batch_size, shuffle=True):\n","        optimizer.zero_grad()\n","\n","        node_emb = model(node_feats, adj_t)\n","        \n","\n","        # Predict the class probabilities on the batch of positive edges using link_predictor\n","        pos_edge = pos_train_edge[edge_id].t()\n","        pos_pred = predictor(node_emb[pos_edge[0]], node_emb[pos_edge[1]])\n","\n","        # Trivial random sampling.\n","        #neg_edge = torch.randint(0, node_feats.size(0), (batch_size,), device=device)\n","        # Sample negative edges (same number as number of positive edges) and predict class probabilities \n","        neg_edge = negative_sampling(edge_index, num_nodes=node_feats.size(0), num_neg_samples=batch_size, method='sparse')\n","        neg_pred = predictor(node_emb[neg_edge[0]], node_emb[neg_edge[1]])\n","\n","         # Compute the corresponding negative log likelihood loss on the positive and negative edges\n","        loss = -torch.log(pos_pred + 1e-15).mean() - torch.log(1 - neg_pred + 1e-15).mean()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n","\n","        optimizer.step()\n","\n","        num_examples = pos_pred.size(0)\n","        total_loss += loss.item() * num_examples\n","        total_examples += num_examples\n","\n","    return total_loss / total_examples"],"metadata":{"id":"fsW6ww-Neuwt","executionInfo":{"status":"ok","timestamp":1652512882099,"user_tz":-120,"elapsed":24,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kjRVAwL4NbGl"},"source":["The performance of a link predictor is evaluated through the metric Hits@K.\n","\n","Hits@K = Fraction of correct links in the top K links (with respect to their scores)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"oR5-_d2OcZim","executionInfo":{"status":"ok","timestamp":1652512882099,"user_tz":-120,"elapsed":24,"user":{"displayName":"Cristian Urbinati","userId":"07869945129592978285"}}},"outputs":[],"source":["@torch.no_grad()\n","def test(model, predictor, data, adj_t, split_edge, evaluator, batch_size):\n","    model.eval()\n","    predictor.eval()\n","\n","    h = model(data, adj_t)\n","\n","    pos_train_edge = split_edge['train']['edge'].to(h.device)\n","    pos_valid_edge = split_edge['valid']['edge'].to(h.device)\n","    neg_valid_edge = split_edge['valid']['edge_neg'].to(h.device)\n","    pos_test_edge = split_edge['test']['edge'].to(h.device)\n","    neg_test_edge = split_edge['test']['edge_neg'].to(h.device)\n","\n","    # ------------------ TRAIN ------------------- #\n","    # Positive edges prediction\n","    pos_train_preds = []\n","    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n","        edge = pos_train_edge[perm].t()\n","        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n","    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n","\n","    # ---------------- VALIDATION ---------------- #\n","    # Positive edges prediction\n","    pos_valid_preds = []\n","    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n","        edge = pos_valid_edge[perm].t()\n","        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n","    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n","    # Negative sampled edges prediction\n","    neg_valid_preds = []\n","    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n","        edge = neg_valid_edge[perm].t()\n","        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n","    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n","\n","    # ------------------- TEST ------------------- #\n","    # Positive edges prediction\n","    pos_test_preds = []\n","    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n","        edge = pos_test_edge[perm].t()\n","        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n","    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n","    # Negative sampled edges prediction\n","    neg_test_preds = []\n","    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n","        edge = neg_test_edge[perm].t()\n","        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n","    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n","\n","    results = {}\n","    # hits@K\n","    for K in [20, 50, 100]:\n","        evaluator.K = K\n","        train_hits = evaluator.eval({\n","            'y_pred_pos': pos_train_pred,\n","            'y_pred_neg': neg_valid_pred,\n","        })[f'hits@{K}']\n","        valid_hits = evaluator.eval({\n","            'y_pred_pos': pos_valid_pred,\n","            'y_pred_neg': neg_valid_pred,\n","        })[f'hits@{K}']\n","        test_hits = evaluator.eval({\n","            'y_pred_pos': pos_test_pred,\n","            'y_pred_neg': neg_test_pred,\n","        })[f'hits@{K}']\n","\n","        results[f'hits@{K}'] = (round(train_hits,2), round(valid_hits,2), round(test_hits,2))\n","\n","    # auc\n","    # results['valid_auc'] = roc_auc_score(\n","    #     y_true = np.concatenate((np.ones(pos_valid_pred.size(0), dtype=int), np.zeros(neg_valid_pred.size(0), dtype=int))),\n","    #     y_score = np.concatenate((pos_valid_pred.numpy(), neg_valid_pred.numpy())) \n","    # )\n","    # results['test_auc'] = roc_auc_score(\n","    #     y_true = np.concatenate((np.ones(pos_test_pred.size(0), dtype=int), np.zeros(neg_test_pred.size(0), dtype=int))),\n","    #     y_score = np.concatenate((pos_test_pred.numpy(), neg_test_pred.numpy()))\n","    # )\n","\n","    return results  "]},{"cell_type":"code","source":["USE_SAGE = True\n","USE_VAL_EDGES_AS_INPUT = False\n","\n","BATCH_SIZE = 128 * 1024\n","INPUT_DIM = dataset.num_features\n","OUTPUT_DIM = dataset.num_classes\n","EPOCHS = 25\n","\n","LR = 5e-3\n","WD = 1e-6\n","EVAL_STEPS = 5\n","\n","\n","split_edge = dataset.get_edge_split()\n","\n","# Use training + validation edges for inference on test set.\n","if USE_VAL_EDGES_AS_INPUT:\n","    val_edge_index = split_edge['valid']['edge'].t()\n","    full_edge_index = torch.cat([edge_index, val_edge_index], dim=-1)\n","    data.full_adj_t = SparseTensor.from_edge_index(full_edge_index).t()\n","    data.adj_t = data.full_adj_t.to_symmetric()\n","\n","data = data.to(device)\n","\n","best_test_hits = 0\n","best_model_history = None\n","best_model_weight = None\n","\n","from sklearn.model_selection import ParameterGrid\n","configs = {\n","    'USE_EMBEDDING_LAYER': [True, False],\n","    'HIDDEN_DIM' : [32],\n","    'DROPOUT' : [0],\n","    'N_LAYERS' : [3],\n","    'SKIP_CONN' : [True],\n","    'POST_PROC_MLP' : [True],\n","}\n","param_grid = ParameterGrid(configs)\n","print(f'Number of combinations: {len(param_grid)}')\n","print('------------------')\n","for dict_ in param_grid:\n","    print(f'Trying configuration {dict_}')\n","    parameter_list = []\n","\n","    #INPUT DATA\n","    if dict_['USE_EMBEDDING_LAYER']:\n","        if data.x is not None:\n","            emb = torch.nn.Embedding(data.num_nodes, INPUT_DIM).to(device)\n","            emb.weight.data.copy_(data.x) # copy data features as initial embedding\n","        else:\n","            emb = torch.nn.Embedding(data.num_nodes, dict_['HIDDEN_DIM']).to(device)  \n","        input_data = emb.weight\n","        parameter_list += (list(emb.parameters()))\n","    else:\n","        input_data = data.x\n","\n","    #MODEL\n","    if USE_SAGE:\n","        model = SAGE2(INPUT_DIM, dict_['HIDDEN_DIM'], dict_['HIDDEN_DIM'], dict_['N_LAYERS'], dict_['DROPOUT'], skip_conn=True).to(device)\n","    else:\n","        model = GCN(INPUT_DIM, dict_['HIDDEN_DIM'], dict_['HIDDEN_DIM'], dict_['N_LAYERS'], dict_['DROPOUT']).to(device)\n","    parameter_list += (list(model.parameters()))\n","\n","    #LINK PREDICTOR\n","    link_predictor = LinkPredictor(dict_['HIDDEN_DIM'], dict_['HIDDEN_DIM'], 1,  dict_['N_LAYERS'], dict_['DROPOUT']).to(device)\n","    parameter_list += (list(link_predictor.parameters()))\n","\n","    optimizer = torch.optim.Adam(parameter_list, lr=LR, weight_decay=WD)\n","\n","    #TRAIN & EVALUATE\n","    history = {}\n","    history['loss'] = []\n","    history['train_hits@20'] = []; history['train_hits@50'] = []; history['train_hits@100'] = []\n","    history['valid_hits@20'] = []; history['valid_hits@50'] = []; history['valid_hits@100'] = []\n","    history['test_hits@20']  = []; history['test_hits@50']  = []; history['test_hits@100']  = []\n","    pbar = tqdm.tqdm(range(EPOCHS))\n","    for epoch in pbar:\n","        loss = train(model, link_predictor, input_data, data.adj_t, split_edge, optimizer, BATCH_SIZE) \n","        history['loss'].append(loss)\n","\n","        if (epoch + 1) % EVAL_STEPS == 0 or epoch == 0:\n","            results = test(model, link_predictor, input_data, data.adj_t, split_edge, evaluator, BATCH_SIZE)\n","            for key, result in results.items():\n","                train_hits, valid_hits, test_hits = result\n","                history[f'train_{key}'].append(train_hits)\n","                history[f'valid_{key}'].append(valid_hits)\n","                history[f'test_{key}'].append(test_hits)\n","\n","        description = f\"Epoch {(epoch + 1):02d} - loss: {loss:.4f} - result: {results}\\t\"\n","        pbar.set_description(description, refresh=True)\n","\n","    print('------------------')\n","    \n","    if max(history['test_hits@100']) > best_test_hits:\n","        best_parameters = dict_\n","        best_model_history = history\n","        best_model_weights = model.state_dict()\n","        best_test_hits = max(history['test_hits@100'])\n","    \n","    del model; del link_predictor\n","    torch.cuda.empty_cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z7m2A6hC5d9Z","outputId":"b92b68e7-31db-4d6a-c92b-b2f83c039ef9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of combinations: 2\n","------------------\n","Trying configuration {'DROPOUT': 0, 'HIDDEN_DIM': 32, 'N_LAYERS': 3, 'POST_PROC_MLP': True, 'SKIP_CONN': True, 'USE_EMBEDDING_LAYER': True}\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/25 [00:00<?, ?it/s]"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pkQsXLyeSHx"},"outputs":[],"source":["print(f'Best parameters: {best_parameters}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_AgL2frZiOM"},"outputs":[],"source":["plt.figure(figsize=(10,5))\n","plt.plot(np.arange(1, EPOCHS+1), best_model_history['loss'], label=\"train loss\")\n","plt.plot(np.arange(0, EPOCHS+1, 5), best_model_history['train_hits@100'], label=\"train Hits@100\")\n","plt.plot(np.arange(0, EPOCHS+1, 5), best_model_history['valid_hits@100'], label=\"val Hits@100\")\n","plt.plot(np.arange(0, EPOCHS+1, 5), best_model_history['test_hits@100'], label=\"test Hits@100\")\n","#plt.plot(np.arange(0, EPOCHS+1, 10), best_model_history['test_auc'], label=\"test auc\")\n","plt.title('Link Prediction on OGB-ddi using GraphSAGE GNN')\n","plt.xlabel('Epochs')\n","plt.ylim(0., 1.)\n","plt.legend(loc='upper left')\n","plt.show()"]}]}